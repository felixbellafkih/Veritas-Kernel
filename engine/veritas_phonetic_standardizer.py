import json
import os
import re

def standardize_lexicon():
    path = 'LEXICON.json'
    if not os.path.exists(path):
        print("‚ùå ERREUR : LEXICON.json introuvable.")
        return

    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # TABLE DE TRANSCRIPTION STRICTE (VTS-v1)
    # C'est la "Loi" de conversion.
    char_map = {
        # --- LES CRITIQUES (A vs ') ---
        'ÿπ': "'",
        'ÿ£': "A", 'ÿ•': "A", 'ÿ¢': "A", 'ÿß': "A", 'ÿ°': "A",
        
        # --- LE RESTE DE L'ALPHABET ---
        'ÿ®': "B", 'ÿ™': "T", 'ÿ´': "TH", 'ÿ¨': "J", 'ÿ≠': "H",
        'ÿÆ': "KH", 'd': "D", 'ÿØ': "D", 'ÿ∞': "DH", 'r': "R",
        'ÿ±': "R", 'z': "Z", 'ÿ≤': "Z", 's': "S", 'ÿ≥': "S",
        'ÿ¥': "SH", 'ÿµ': "S", 'ÿ∂': "D", 'ÿ∑': "T", 'ÿ∏': "Z",
        'ÿ∫': "GH", 'f': "F", 'ŸÅ': "F", 'q': "Q", 'ŸÇ': "Q",
        'k': "K", 'ŸÉ': "K", 'l': "L", 'ŸÑ': "L", 'm': "M",
        'ŸÖ': "M", 'n': "N", 'ŸÜ': "N", 'h': "H", 'Ÿá': "H",
        'w': "W", 'Ÿà': "W", 'y': "Y", 'Ÿä': "Y", 'Ÿâ': "Y",
        'ÿ©': "T" # Ta Marbuta souvent T ou H, on fixe T pour la racine
    }

    corrections = 0
    errors = 0

    for item in data['universal_functions']:
        original_root_str = item['root']
        
        # 1. Extraction de la partie Arabe (Tout ce qui est avant la parenth√®se ou le premier espace)
        # On nettoie les tirets arabes s'il y en a
        arabic_part = original_root_str.split('(')[0].strip().replace('-', '').replace(' ', '')
        
        # 2. Reconstruction de la translitt√©ration (Le code entre parenth√®ses)
        new_translit = []
        try:
            for char in arabic_part:
                if char in char_map:
                    new_translit.append(char_map[char])
                else:
                    # Caract√®re non mapp√© (ignorer ou signaler)
                    pass
            
            # On joint avec des tirets pour le format standard (ex: A-K-L)
            new_code = "-".join(new_translit)
            
            # 3. Reconstruction de la cha√Æne compl√®te "ÿ£-ŸÉ-ŸÑ (A-K-L)"
            # On remet les tirets dans l'arabe aussi pour faire propre
            arabic_dashed = "-".join(list(arabic_part))
            new_root_str = f"{arabic_dashed} ({new_code})"
            
            # 4. Application si diff√©rent
            if new_root_str != original_root_str:
                # On v√©rifie sp√©cifiquement les corrections A vs '
                if ("'" in new_code and "A" in original_root_str) or ("A" in new_code and "'" in original_root_str):
                     print(f"  üîß FIX: {original_root_str} -> {new_root_str}")
                
                item['root'] = new_root_str
                corrections += 1
                
        except Exception as e:
            print(f"  ‚ö†Ô∏è ERREUR sur {original_root_str}: {e}")
            errors += 1

    data['version'] = f"{data.get('version', '1.0').split('-')[0]}-Phonetic-Standard"

    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

    print("-" * 60)
    print(f"‚úÖ STANDARDISATION TERMIN√âE.")
    print(f"üìä Entr√©es corrig√©es : {corrections}")
    print(f"üõ°Ô∏è Standard VTS-v1 appliqu√© : 100% des 'Ain sont (') et 100% des Alif sont (A).")

if __name__ == "__main__":
    standardize_lexicon()
